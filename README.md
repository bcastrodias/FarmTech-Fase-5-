# FarmTech-Fase-5- # üìä **Previs√£o do Rendimento das Safras com Machine Learning**

Este reposit√≥rio cont√©m um projeto que utiliza diferentes algoritmos de **Machine Learning** para prever o **rendimento das safras** com base em vari√°veis clim√°ticas. O objetivo √© comparar cinco modelos preditivos: **Regress√£o Linear**, **SVM**, **Random Forest**, **Decision Tree** e **XGBoost**, avaliando seu desempenho com **valida√ß√£o cruzada** e diversas m√©tricas de erro.

---

## üöÄ **Estrutura do Reposit√≥rio**

1. **Introdu√ß√£o**
2. **Carregamento e Prepara√ß√£o dos Dados**
3. **An√°lise Explorat√≥ria de Dados (EDA)**
4. **Pr√©-processamento de Dados**
5. **Treinamento e Avalia√ß√£o dos Modelos**
6. **Compara√ß√£o de Modelos**
7. **Conclus√µes**

---

## üìã **Passo a Passo do Jupyter Notebook**

### 1. **Introdu√ß√£o**
   O objetivo deste trabalho √© prever o **rendimento das safras** com base em vari√°veis clim√°ticas como **precipita√ß√£o**, **temperatura** e **umidade**. O projeto explora a utiliza√ß√£o de cinco modelos de **Machine Learning** para prever esse rendimento e comparar seus desempenhos.

### 2. **Carregamento e Prepara√ß√£o dos Dados**
   O primeiro passo √© o **carregamento dos dados**. Os dados clim√°ticos e de rendimento das safras foram carregados em um **DataFrame** do **Pandas**. Em seguida, os dados passaram por uma an√°lise inicial para verificar **valores faltantes** ou **inconsist√™ncias**.

---

### 3. **An√°lise Explorat√≥ria de Dados (EDA)**
   Ap√≥s o carregamento, a **an√°lise explorat√≥ria** foi realizada para entender as **caracter√≠sticas** dos dados. A **EDA** inclui:
   - **Estat√≠sticas descritivas**: Foram calculadas **m√©dia**, **desvio padr√£o**, **m√≠nimos**, **m√°ximos** e os **quartis** de cada vari√°vel, como **precipita√ß√£o**, **umidade**, **temperatura** e **rendimento**.
   - **Correla√ß√£o entre vari√°veis**: Foi calculada a **matriz de correla√ß√£o** para verificar como as vari√°veis se relacionam entre si. A an√°lise revelou que **precipita√ß√£o** e **umidade** estavam mais fortemente correlacionadas com outras vari√°veis, mas **rendimento** teve baixa correla√ß√£o com as vari√°veis clim√°ticas, sugerindo que outros fatores podem influenciar o desempenho das safras.
   
---

### 4. **Pr√©-processamento de Dados**
   Ap√≥s a an√°lise inicial, os dados foram preparados para o treinamento dos modelos. As etapas de **pr√©-processamento** incluem:
   - **Escalonamento das Vari√°veis**: Foi utilizado **StandardScaler** para padronizar os dados e garantir que todas as vari√°veis tivessem a mesma escala.
   - **Divis√£o em Conjunto de Treinamento e Teste**: O conjunto de dados foi dividido em **80%** para treinamento e **20%** para teste utilizando a fun√ß√£o **train_test_split** do **sklearn**.

---

### 5. **Treinamento e Avalia√ß√£o dos Modelos**
   Cinco algoritmos de **Machine Learning** foram treinados para prever o **rendimento das safras**:
   - **Regress√£o Linear**: Modelo simples que modela uma rela√ß√£o linear entre as vari√°veis.
   - **SVM (Support Vector Machine)**: Modelo que encontra o hiperplano que melhor separa as observa√ß√µes.
   - **Random Forest**: Modelo baseado em m√∫ltiplas √°rvores de decis√£o.
   - **Decision Tree**: √Årvore de decis√£o que divide os dados em segmentos baseados nas vari√°veis.
   - **XGBoost**: Modelo de **boosting** que utiliza v√°rias √°rvores para melhorar a precis√£o.
   
   Cada modelo foi avaliado com **valida√ß√£o cruzada** e comparado com as m√©tricas de **RMSE**, **R¬≤**.

---

### 6. **Compara√ß√£o de Modelos**
   Ap√≥s o treinamento, todos os modelos foram comparados com base nas m√©tricas de **erro** e **capacidade explicativa**. **Random Forest** apresentou o melhor desempenho, com um **R¬≤ de 0.9999** e **RMSE baixo**, sendo o modelo mais equilibrado. A **Regress√£o Linear** mostrou um **R¬≤ de 1.0**, mas indicou **sobreajuste**. O modelo **SVM** teve um desempenho ruim com **R¬≤ negativo** e **RMSE muito alto**.

---

### 7. **Conclus√µes**
   O modelo **Random Forest** foi o mais eficaz para prever o rendimento das safras, apresentando um bom equil√≠brio entre erro baixo e alta capacidade explicativa. A **Regress√£o Linear**, embora tenha mostrado excelentes resultados nos dados de treino, indicou **sobreajuste**, o que comprometeria a generaliza√ß√£o para novos dados. O **SVM** n√£o foi adequado para esse tipo de problema, dado seu desempenho insatisfat√≥rio. Os modelos **Decision Tree** e **XGBoost** tamb√©m foram eficazes, mas o **Random Forest** mostrou-se mais robusto.

---



